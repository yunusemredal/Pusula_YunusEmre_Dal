{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1e60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json,logging\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Logging ayarı\n",
    "LOG_FMT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FMT)\n",
    "RND_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a97d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class beforeEDA:\n",
    "    @staticmethod\n",
    "    def ensureDir(path: str):\n",
    "        \"\"\"Klasör yoksa oluştur.\"\"\"\n",
    "        if not path:\n",
    "            return\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def saveJson(obj: Any, path: str):\n",
    "        \"\"\"JSON dosyası kaydet.\"\"\"\n",
    "        dirn = os.path.dirname(path) or \".\"\n",
    "        beforeEDA.ensureDir(dirn)\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(obj, f, ensure_ascii=False, indent=2,default=str)\n",
    "\n",
    "    @staticmethod\n",
    "    def readInput(inputPath: str, sheetName=0) -> pd.DataFrame:\n",
    "        \"\"\"Excel/CSV oku ve DataFrame döndür.\"\"\"\n",
    "        ext = os.path.splitext(inputPath)[1].lower()\n",
    "        if ext in [\".xls\", \".xlsx\"]:\n",
    "            logging.info(\"Excel okundu: %s (sheet=%s)\", inputPath, sheetName)\n",
    "            df = pd.read_excel(inputPath, sheet_name=sheetName)\n",
    "        elif ext == '.csv':\n",
    "            logging.info(\"CSV okundu: %s\", inputPath)\n",
    "            df = pd.read_csv(inputPath)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def excelToCsv(excel_path: str, csv_path: str, sheet_name=0, encoding=\"utf-8-sig\"):\n",
    "        \"\"\"Excel'i CSV'ye çevir.\"\"\"\n",
    "        df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "        beforeEDA.ensureDir(os.path.dirname(csv_path) or \".\")\n",
    "        df.to_csv(csv_path, index=False, encoding=encoding)\n",
    "        logging.info(\"Excel to CSV done: %s -> %s\", excel_path, csv_path)\n",
    "        return csv_path\n",
    "\n",
    "    @staticmethod\n",
    "    def saveJsonSummary(csv_path: str, jsonPath: str, sampleValues=5):\n",
    "        \"\"\"CSV özetini JSON olarak kaydet.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        summary = {}\n",
    "        n = len(df)\n",
    "        for col in df.columns:\n",
    "            col_data = df[col]\n",
    "            non_null = col_data.dropna()\n",
    "            dtype = str(col_data.dtype)\n",
    "            missing = col_data.isna().sum()\n",
    "            unique = int(col_data.nunique(dropna=True))\n",
    "            missing_pct = round(missing / n * 100, 3)\n",
    "            sample = non_null.unique()[:sampleValues].tolist()\n",
    "            col_summary = {\n",
    "                \"dtype\": dtype,\n",
    "                \"missing\": missing,\n",
    "                \"missing_pct\": missing_pct,\n",
    "                \"unique\": unique,\n",
    "                \"sample\": sample\n",
    "            }\n",
    "            if pd.api.types.is_numeric_dtype(col_data):\n",
    "                col_summary.update({\n",
    "                    \"mean\": round(non_null.mean(), 3) if not non_null.empty else None,\n",
    "                    \"std\": round(non_null.std(), 3) if not non_null.empty else None,\n",
    "                    \"min\": round(non_null.min(), 3) if not non_null.empty else None,\n",
    "                    \"25%\": round(non_null.quantile(0.25), 3) if not non_null.empty else None,\n",
    "                    \"50%\": round(non_null.median(), 3) if not non_null.empty else None,\n",
    "                    \"75%\": round(non_null.quantile(0.75), 3) if not non_null.empty else None,\n",
    "                    \"max\": round(non_null.max(), 3) if not non_null.empty else None,\n",
    "                })\n",
    "            else:\n",
    "                top_counts = non_null.value_counts().head(10).to_dict()\n",
    "                col_summary[\"top_values\"] = {str(k): int(v) for k, v in top_counts.items()}\n",
    "            summary[col] = col_summary\n",
    "        beforeEDA.saveJson(summary, jsonPath)\n",
    "        logging.info(\"CSV özet JSON kaydedildi: %s\", jsonPath)\n",
    "        return df, summary\n",
    "\n",
    "    @staticmethod\n",
    "    def parseMultiLabelColumn(series: pd.Series, sep=\",\") -> List[List[str]]:\n",
    "        \"\"\"Multi-label kolonları liste haline getir.\"\"\"\n",
    "        def splitAndClean(x):\n",
    "            if pd.isna(x): return []\n",
    "            if not isinstance(x, str): x = str(x)\n",
    "            parts = [p.strip() for p in x.split(sep) if p.strip() != \"\"]\n",
    "            return parts\n",
    "        return series.map(splitAndClean).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07980012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdaAnalysis:\n",
    "    @staticmethod\n",
    "    def eda_Analysis(df: pd.DataFrame, outDir: str, LastJsonPath: str, topNCat=10):\n",
    "        beforeEDA.ensureDir(outDir)\n",
    "        plotsDir = os.path.join(outDir, \"Plots\")\n",
    "        beforeEDA.ensureDir(plotsDir)\n",
    "        logging.info(\"EDA Başlıyor. \")\n",
    "        nRows, nCols = df.shape\n",
    "        numericCols = df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "        categoricalCols = df.select_dtypes(include=[\"object\",\"category\"]).columns.to_list()\n",
    "\n",
    "        edaResult = {\n",
    "            \"shape\": {\"rows\": nRows, \"cols\": nCols},\n",
    "            \"numeric_columns\": numericCols,\n",
    "            \"categorical_columns\": categoricalCols,\n",
    "            \"missing\": df.isna().sum().to_dict(),\n",
    "            \"data_types\": df.dtypes.astype(str).to_dict(),\n",
    "        }\n",
    "\n",
    "        # Numeric stats\n",
    "        numStats = {}\n",
    "        for col in numericCols:\n",
    "            ser = df[col]\n",
    "            stats = ser.describe().to_dict()\n",
    "            stats[\"skew\"] = float(ser.dropna().skew()) if ser.dropna().shape[0] > 2 else None\n",
    "            numStats[col] = {k: (float(v) if pd.notna(v) else None) for k, v in stats.items()}\n",
    "\n",
    "            # Histogram\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.histplot(ser.dropna(), kde=True)\n",
    "            plt.title(f\"{col} Histogram\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plotsDir, f\"{col}_Hist.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # Boxplot\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.boxplot(x=ser.dropna())\n",
    "            plt.title(f\"{col} Boxplot\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plotsDir, f\"{col}_Box.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        edaResult[\"Numeric_Stats\"] = numStats\n",
    "\n",
    "        # Korelasyon\n",
    "        try:\n",
    "            corr = df[numericCols].corr()\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "            plt.title(\"Numerik Korelasyon Matrix\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plotsDir, \"korelasyonMatrix.png\"))\n",
    "            plt.close()\n",
    "            edaResult[\"Korelasyon_Matrix\"] = corr.to_dict()\n",
    "        except Exception as e: \n",
    "            logging.warning(\"Korelasyon hesaplanamadı: %s\", e)\n",
    "\n",
    "        # Target analiz\n",
    "        target = \"TedaviSuresi\"\n",
    "        if target in df.columns:\n",
    "            tser = df[target]\n",
    "            edaResult[\"target\"] = {\n",
    "                \"missing\": int(tser.isna().sum()),\n",
    "                \"describe\": tser.describe().to_dict() if pd.api.types.is_numeric_dtype(tser) else None\n",
    "            }\n",
    "            if pd.api.types.is_numeric_dtype(tser):\n",
    "                plt.figure(figsize=(6,4))\n",
    "                sns.histplot(tser.dropna(), kde=True)\n",
    "                plt.title(f\"Hedef ({target}) dağılımı\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(plotsDir, f\"{target}_Hist.png\"))\n",
    "                plt.close()\n",
    "\n",
    "        beforeEDA.saveJson(edaResult, LastJsonPath)\n",
    "        logging.info(\"EDA Tamamlandı\")\n",
    "        return edaResult, plotsDir\n",
    "\n",
    "    @staticmethod\n",
    "    def CleanData(df: pd.DataFrame, drop_dupes_on: List[str]=None, drop_missing_threshold: float=0.5) -> pd.DataFrame:\n",
    "        dfc = df.copy()\n",
    "        for col in dfc.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "            dfc[col] = dfc[col].astype(str).map(lambda x: x.strip() if pd.notna(x) else x)\n",
    "            dfc.loc[dfc[col].isin([\"\", \"nan\", \"None\", \"NoneType\"]), col] = np.nan\n",
    "\n",
    "        # Kolonları eksik veri yüzdesine göre düşür\n",
    "        colMissingPct = dfc.isna().mean()\n",
    "        dropCols = colMissingPct[colMissingPct > drop_missing_threshold].index.tolist()\n",
    "        if dropCols:\n",
    "            logging.info(\"Sütunlar siliniyor (yüksek eksik veri): %s\", dropCols)\n",
    "            dfc.drop(columns=dropCols, inplace=True)\n",
    "\n",
    "        # Duplicates\n",
    "        if drop_dupes_on:\n",
    "            before = len(dfc)\n",
    "            dfc.drop_duplicates(subset=drop_dupes_on, keep=\"first\", inplace=True)\n",
    "            after = len(dfc)\n",
    "            logging.info(\"Duplicate (subset=%s) temizlendi: %d -> %d\", drop_dupes_on, before, after)\n",
    "        else:\n",
    "            if \"HastaNo\" in dfc.columns:\n",
    "                before = len(dfc)\n",
    "                dfc.drop_duplicates(subset=[\"HastaNo\"], keep=\"first\", inplace=True)\n",
    "                after = len(dfc)\n",
    "                logging.info(\"Duplicate (HastaNo) temizlendi: %d -> %d\", before, after)\n",
    "\n",
    "        # Tip dönüşümleri\n",
    "        for col in dfc.columns:\n",
    "            try:\n",
    "                pd.to_numeric(dfc[col].dropna().head(10))\n",
    "                dfc[col] = pd.to_numeric(dfc[col], errors='ignore')\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Eksikleri doldur\n",
    "        for col in dfc.select_dtypes(include=[\"object\"]).columns:\n",
    "            if dfc[col].isna().sum() > 0:\n",
    "                try:\n",
    "                    mode = dfc[col].mode(dropna=True)[0]\n",
    "                    dfc[col].fillna(mode, inplace=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        for col in dfc.select_dtypes(include=[np.number]).columns:\n",
    "            if dfc[col].isna().sum() > 0:\n",
    "                med = dfc[col].median()\n",
    "                dfc[col].fillna(med, inplace=True)\n",
    "\n",
    "        return dfc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afad9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    @staticmethod\n",
    "    def feature_engineering(df: pd.DataFrame, ml_columns: List[str]=None, top_k: int=20) -> Tuple[pd.DataFrame, Dict[str,List[str]]]:\n",
    "        df_fe = df.copy()\n",
    "        mlColFeatures = {}\n",
    "        if not ml_columns:\n",
    "            ml_columns = [c for c in df_fe.columns if c in [\"KronikHastalik\",\"Alerji\"]]\n",
    "        for col in ml_columns:\n",
    "            if col not in df_fe.columns:\n",
    "                continue\n",
    "            lists = beforeEDA.parseMultiLabelColumn(df_fe[col], sep=\",\")\n",
    "            flat = [item for sublist in lists for item in sublist]\n",
    "            if not flat:\n",
    "                continue\n",
    "            topLabels = pd.Series(flat).value_counts().head(top_k).index.tolist()\n",
    "            mlColFeatures[col] = topLabels\n",
    "\n",
    "            mlb = MultiLabelBinarizer(classes=topLabels)\n",
    "            binarized = mlb.fit_transform(lists)\n",
    "\n",
    "            col_names = [f\"{col}__{label.replace(' ', '_')}\" for label in mlb.classes_]\n",
    "            tmp = pd.DataFrame(binarized, columns=col_names, index=df_fe.index)\n",
    "            df_fe = pd.concat([df_fe, tmp], axis=1)\n",
    "            df_fe[f\"{col}__count\"] = [len(x) for x in lists]\n",
    "        return df_fe, mlColFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998aa0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class afterEDA:\n",
    "    @staticmethod\n",
    "    def _get_ohe_feature_names(ohe: OneHotEncoder, cols: List[str]) -> List[str]:\n",
    "        try:\n",
    "            names = ohe.get_feature_names_out(cols).tolist()\n",
    "        except Exception:\n",
    "            names = []\n",
    "            categories = getattr(ohe, \"categories_\", [])\n",
    "            for i, col in enumerate(cols):\n",
    "                cats = categories[i]\n",
    "                for cat in cats:\n",
    "                    names.append(f\"{col}__{str(cat)}\")\n",
    "        return names\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_model_data(df: pd.DataFrame, target_col: str=\"TedaviSuresi\", out_csv: str=\"model_ready.csv\"):\n",
    "        if target_col in df.columns:\n",
    "            y = df[target_col].copy()\n",
    "            X = df.drop(columns=[target_col])\n",
    "        else:\n",
    "            y = None\n",
    "            X = df.copy()\n",
    "\n",
    "        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "        logging.info(\"Model hazırlık: numeric=%s, categorical=%s\", numeric_cols, categorical_cols)\n",
    "\n",
    "        numeric_pipeline = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "        categorical_pipeline = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "        transformers = []\n",
    "        if numeric_cols:\n",
    "            transformers.append((\"num\", numeric_pipeline, numeric_cols))\n",
    "        if categorical_cols:\n",
    "            transformers.append((\"cat\", categorical_pipeline, categorical_cols))\n",
    "\n",
    "        preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\", sparse_threshold=1.0)\n",
    "        X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "        feature_names = []\n",
    "        if numeric_cols:\n",
    "            feature_names.extend(numeric_cols)\n",
    "        if categorical_cols:\n",
    "            ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "            cat_names = afterEDA._get_ohe_feature_names(ohe, categorical_cols)\n",
    "            feature_names.extend(cat_names)\n",
    "\n",
    "        if hasattr(X_trans, \"toarray\"):\n",
    "            X_arr = X_trans.toarray()\n",
    "        else:\n",
    "            X_arr = np.asarray(X_trans)\n",
    "\n",
    "        model_df = pd.DataFrame(X_arr, columns=feature_names)\n",
    "        if y is not None:\n",
    "            model_df[target_col] = y.reset_index(drop=True)\n",
    "\n",
    "        beforeEDA.ensureDir(os.path.dirname(out_csv) or \".\")\n",
    "        model_df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "        up_out = os.path.join(os.path.dirname(out_csv), \"MODEL_READY.csv\")\n",
    "        model_df.to_csv(up_out, index=False, encoding=\"utf-8-sig\")\n",
    "        logging.info(\"Model-ready CSV kaydedildi: %s ve %s\", out_csv, up_out)\n",
    "        return model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d420acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(input_path: str,\n",
    "                 outDir: str = \"outputs\",\n",
    "                 sheet_name=0,\n",
    "                 drop_missing_threshold=0.5,\n",
    "                 top_k_labels=20):\n",
    "    beforeEDA.ensureDir(outDir)\n",
    "    plots_dir = os.path.join(outDir, \"plots\")\n",
    "    beforeEDA.ensureDir(plots_dir)\n",
    "\n",
    "    ext = os.path.splitext(input_path)[1].lower()\n",
    "    if ext in [\".xls\", \".xlsx\"]:\n",
    "        csv_path = os.path.join(outDir, \"converted_from_excel.csv\")\n",
    "        beforeEDA.excelToCsv(input_path, csv_path, sheet_name=sheet_name)\n",
    "    else:\n",
    "        csv_path = input_path\n",
    "\n",
    "    csv_summary_path = os.path.join(outDir, \"summary.json\")\n",
    "    df, summary = beforeEDA.saveJsonSummary(csv_path, csv_summary_path)\n",
    "\n",
    "    last_json_path = os.path.join(outDir, \"last.json\")\n",
    "    eda_result, plots_dir = EdaAnalysis.eda_Analysis(df, outDir=outDir, LastJsonPath=last_json_path)\n",
    "\n",
    "    df_clean = EdaAnalysis.CleanData(df, drop_dupes_on=[\"HastaNo\"] if \"HastaNo\" in df.columns else None,\n",
    "                                     drop_missing_threshold=drop_missing_threshold)\n",
    "    cleaned_path = os.path.join(outDir, \"cleaned.csv\")\n",
    "    df_clean.to_csv(cleaned_path, index=False, encoding=\"utf-8-sig\")\n",
    "    logging.info(\"cleaned.csv kaydedildi: %s\", cleaned_path)\n",
    "\n",
    "    ml_cols = [c for c in df_clean.columns if c in [\"KronikHastalik\", \"Alerji\", \"Tanilar\"]]\n",
    "    if ml_cols:\n",
    "        df_fe, ml_features = Feature.feature_engineering(df_clean, ml_columns=ml_cols, top_k=top_k_labels)\n",
    "        logging.info(\"Feature engineering tamamlandı, eklenen çoklu etiket sütunları: %s\", ml_features)\n",
    "    else:\n",
    "        df_fe = df_clean\n",
    "        ml_features = {}\n",
    "\n",
    "    model_ready_path = os.path.join(outDir, \"model_ready.csv\")\n",
    "    model_df = afterEDA.prepare_model_data(df_fe, target_col=\"TedaviSuresi\", out_csv=model_ready_path)\n",
    "\n",
    "    final_notes = {\n",
    "        \"generated_files\": {\n",
    "            \"summary_json\": csv_summary_path,\n",
    "            \"eda_last_json\": last_json_path,\n",
    "            \"cleaned_csv\": cleaned_path,\n",
    "            \"model_ready_csv\": model_ready_path,\n",
    "            \"model_ready_csv_upper\": os.path.join(outDir, \"MODEL_READY.csv\"),\n",
    "            \"plots_dir\": plots_dir\n",
    "        },\n",
    "        \"multilabel_features\": ml_features\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(last_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            last = json.load(f)\n",
    "    except Exception:\n",
    "        last = {}\n",
    "    last.update({\"pipeline_final\": final_notes})\n",
    "    beforeEDA.saveJson(last, last_json_path)\n",
    "    logging.info(\"Pipeline tamamlandı. Tüm çıktılar %s içinde.\", outDir)\n",
    "    return final_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef09bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:51:51,388 - INFO - Excel to CSV done: Talent_Academy_Case_DT_2025.xlsx -> Veysel\\converted_from_excel.csv\n",
      "2025-09-06 21:51:51,444 - INFO - CSV özet JSON kaydedildi: Veysel\\summary.json\n",
      "2025-09-06 21:51:51,450 - INFO - EDA Başlıyor. \n",
      "2025-09-06 21:51:52,107 - INFO - EDA Tamamlandı\n",
      "2025-09-06 21:51:52,135 - INFO - Duplicate (subset=['HastaNo']) temizlendi: 2235 -> 404\n",
      "C:\\Users\\yunus\\AppData\\Local\\Temp\\ipykernel_2788\\1094889377.py:110: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  dfc[col] = pd.to_numeric(dfc[col], errors='ignore')\n",
      "C:\\Users\\yunus\\AppData\\Local\\Temp\\ipykernel_2788\\1094889377.py:119: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfc[col].fillna(mode, inplace=True)\n",
      "2025-09-06 21:51:52,142 - INFO - cleaned.csv kaydedildi: Veysel\\cleaned.csv\n",
      "c:\\Users\\yunus\\Desktop\\Code\\PusulaCaseForDataScience\\pusulaTask\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) [\"'DORSALJİ\", 'ARTİKÜLER KIKIRDAK DİĞER BOZUKLUKLARI', 'Akromiyoklavikuler eklem burkulma ve gerilmesi', 'Akut apandisit', 'Akut peptik ülser', 'Algonörodistrofi', 'Allerjik rinit', 'Alt ekstremite mononöropatileri', 'Anksiyete bozukluğu', 'Anüs ve rektumun diğer tanımlanmış hastalıkları', 'Aort stenozu', 'Artroz', 'Astım', 'Aterosklerotik kardiyovasküler hastalık', 'Atrial fibrilasyon ve flutter', 'Ayak bileği ve ayak düzeyinde derin peroneal sinir yaralanması', 'Ayak bileği ve ayak düzeyinde eklem ve ligamentlerin çıkık', 'Ayak bileği ve ayak düzeyinde kas ve tendon yaralanması', 'Ayak bileği ve ayağın diğer ve tanımlanmamış yaralanmaları', 'Ayak bileği ve ayağın yüzeysel yaralanması', 'Ayak kırığı', 'Aşil tendiniti', 'Aşil tendon yaralanması', 'BACAK', 'Baldır düzeyinde peroneal sinir yaralanması', 'Baş ağrısı', 'Bel ağrısı', 'Bell palsisi', 'Benign prostat hiperplazisi', 'Beyincik malign neoplazmı', 'Birinci karpometakarpal eklemin artrozu', 'Biseps diğer kısımlarının kas ve tendon yaralanması', 'Bisipital tendinit', 'Böbrek yetmezlikleri', 'BİRDEN FAZLA YER', 'COVID-19', 'DISPNE', 'Deliryum', 'Dermatofitoz', 'Dirsek eklem ve ligamentlerinin çıkık', 'Dirsek çıkığı', 'Dispne', 'Diyabetes mellitüs', 'Diz (anterior) (posterior) çapraz ligament burkulma ve gerilmesi', 'Dizin diğer bursiti', 'Dizin iç bozukluğu', 'Düşme', 'Eklem diğer bozuklukları', 'Eklem kontraktürü', 'Eklem \\xadağrısı', 'Eklemde ağrı', 'Eklemin diğer instabilitesi', 'Eklemin kontraktürü', 'El bileği ve el düzeyinde baş parmak ekstansör kas ve tendonunun yaralanması', 'El bileği ve el düzeyinde baş parmak intirinsik kas ve tendonunun yaralanması', 'El bileği ve el düzeyinde eklem ve ligame`ntlerin çıkık', 'El bileği ve el düzeyinde kas ve tendon yaralanması', 'Epilepsi', 'Esansiyel (primer) hipertansiyon', 'Fekal inkontinans', 'Femur diğer kısımlarının kırıkları', 'Femur kırığı', 'Femur şaft kırığı', 'Femurun longitudinal redüksiyon defekti', 'Fobik anksiyete bozukluğu', 'Ganglion', 'HEMARTROZ', 'Halluks valgus (kazanılmış)', 'Hematüri', 'Hipotroidizm', 'Humerus alt uç kırığı', 'Humerus üst uç kırığı', 'Juvenil ve adölesan idiopatik skolyoz', 'Kalkaneal spur', 'Kalp pili ayar ve kullanımı', 'Kalp yetmezliği', 'Kalsifik tendinit', 'Karaciğer nakli', 'Karpal tünel sendromu', 'Karın ağrısı diğer ve tanımlanmamış', 'Kas bozuklukları', 'Kas zorlanması (muscular strain)', 'Kasın diğer bozuklukları', 'Kifoz ve lordoz', 'Koksartroz [kalça artrozu]', 'Kondrokostal kavşak sendromu [Tietze]', 'Konjestif kalp yetmezliği', 'Kronik iskemik kalp hastalığı', 'Kısa aşil tendonu (kazanılmış)', 'Lateral epikondilit', 'Lateral malleol kırığı', 'Lenfödem', 'Lomber omurga ve pelvis kırığı', 'Lomber vertebra ve pelvis eklem ve ligamentlerinin çıkık', 'Lumbar ve diğer intervertebral disk bozuklukları', 'Magnezyum eksikliği', 'Medial epikondilit', 'Medial malleol kırığı', 'Medial menisküsün posterior boynuzunun diğer yerleşim bozuklukları', 'Meme malign neoplazmı', 'Menisküslerin yerleşim bozukluğu', 'Meralgia paraestetika', 'Mesanenin diğer bozuklukları', 'Mesanenin nöromusküler disfonksiyonu', 'Metakarpal kemik diğer kırığı', 'Metakarpal kemiklerin birden fazla kırıkları', 'Metatarsalji', 'Mitral kapak yetmezliği', 'Mitral ve triküspid kapak bozuklukları', 'Miyopatiler', 'Mononöropatiler', 'Multipl skleroz', 'Nöralji ve nörit', 'OMUZ BÖLGESİ', 'OMUZUN KALSIFIK TENDINITI', 'Olekranon bursiti', 'Omuz rotator cuff tendon yaralanması', 'Omuzun adezif kapsüliti', 'Ortopedik eklem implantı', 'Osteoporoz', 'Parapleji', 'Parapleji ve tetrapleji', 'Parkinson hastalığı', 'Parmak (lar)ın deformitesi', 'Parmak diğer kırığı', 'Parmağın fleksor kas ve tendonunun diğer yaralanması', 'Patellanın diğer yerleşim bozuklukları', 'Patellanın rekürren sublüksasyonu', 'Patellofemoral bozukluklar', 'Pertrokanterik kırık', 'Plantar fasial fibromatozis', 'Pnömoni', 'Popliteal boşluğun sinovial kisti [Baker]', 'Postural kifoz', 'Primer gonartroz', 'Radius üst ucu kırığı', 'Rotator kuf sendromu', 'SAKRAL VE SAKROKOKSİGEAL BÖLGE', 'Saf hiperkolesterolemi', 'Safra taşı', 'Safra yolu taşı', 'Sekonder koksartroz', 'Serebrovasküler hastalık', 'Serebrovasküler hastalıklar', 'Serebrovasküler hastalıklar diğer', 'Servikal disk bozuklukları', 'Sinovit ve tenosinovit', 'Sinovya ve tendonun diğer bozuklukları', 'Skolyoz', 'Solunum bozuklukları', 'Spastik hemipleji', 'Spastik serebral palsi', 'Spinal stenoz', 'Spondilolistezis', 'Spondiloz', 'Sternoklavikuler eklem burkulma ve gerilmesi', 'Subaraknoid hemoraji', 'TANIMLANMAMIŞ', 'TORASİK BÖLGE', 'Tek başına fibula kırığı', 'Temporomandibüler eklem bozuklukları', 'Tendonun (kılıf) diğer kontraktürü', 'Tetik parmak', 'Tibia üst uç kırığı', 'Trokanterik bursit', 'VERTEBRADA', 'Viral enfeksiyonlar', 'Vitamin D eksikliği', 'Vitaminlerin eksikliği', 'ayak bileği hariç', 'ayak bileği ve ayak', 'bacak', 'başka yerde sınıflanmamış', 'başka yerde sınıflanmış diğer hastalıklarda', 'başka yerde sınıflanmış hastalıklarda', 'bilateral', 'burkulma', 'burkulma ve gerilmesi', 'demans üzerine eklenen', 'diğer radikulopati ile', 'diğer sendromları', 'diğer tanımlanmış', 'diğe\\xadr', 'di̇ğer', 'el', 'eski yırtık veya yaralanmaya bağlı', 'hemoraji veya perforasyon yok', 'kapalı', 'kol', 'kolanjit veya kolesistit olmadan', 'myelopati ile (G99.2*)', 'omuz bölgesi', 'patolojik kırıksız', 'pelvik bölge ve kalça', 'peritoneal apse ile', 'radikülopati ile', 'tanımlanmamış bölgelerin', 'tanımlanmamış organizmalar', 'tanımlanmış', 'tanımlanmış virüs', 'yer tanımlanmamış', 'yeri tanımlanmamış', '\\xadDİĞER', 'Üriner inkontinans', 'Üriner sistem enfeksiyonu', 'Üriner sistemin diğer bozuklukları', 'İliotibial band sendromu', 'İntervertebra\"l disk bozuklukları', 'İntrehepatik safra yolu karsinomu', 'İşemede diğer zorluklar', '\\u200b DİĞER', '\\u200b SERVİKOTORASİK BÖLGE', '\\u200b ayak ve ayak bileği', '\\u200b tanımlanmamış', '\\u200b şimdiki', '\\u200bAlgonörodistrofi', '\\u200bVitamin D eksikliği'] will be ignored\n",
      "  warnings.warn(\n",
      "2025-09-06 21:51:52,158 - INFO - Feature engineering tamamlandı, eklenen çoklu etiket sütunları: {'KronikHastalik': ['Myastenia gravis', 'Hiportiroidizm', 'Aritmi', 'Limb-Girdle Musküler Distrofi', 'Hipertiroidizm', 'Astım', 'Duchenne Musküler Distrofisi', 'Kalp yetmezliği', 'Fascioscapulohumeral Distrofi', 'Hipertansiyon', 'Becker Musküler Distrofisi', 'Diyabet', 'Polimiyozit', 'Guatr', 'Hipotirodizm'], 'Alerji': ['Polen', 'POLEN', 'Toz', 'TOZ', 'NOVALGIN', 'Sucuk', 'CORASPIN', 'ARVELES', 'Yer Fıstığı', 'Novalgin', 'SUCUK', 'GRİPİN', 'VOLTAREN', 'GRIPIN', 'Voltaren', 'Volteren'], 'Tanilar': ['DORSALJİ', 'DİĞER', 'tanımlanmamış', 'LUMBOSAKRAL BÖLGE', 'İntervertebral disk bozuklukları', 'Omuzun darbe sendromu', 'SERVİKOTORASİK BÖLGE', 'SERVİKAL BÖLGE', 'Eklem ağrısı', 'diğer', 'Dorsalji', 'Menisküs yırtığı', 'şimdiki', 'Fibromiyalji', 'Radikülopati', 'Gonartroz [diz ekleminin artrozu]', 'Kondromalazia patella', 'Boyun ağrısı', 'birden fazla yer', 'Ekstremite ağrısı']}\n",
      "2025-09-06 21:51:52,164 - INFO - Model hazırlık: numeric=['HastaNo', 'Yas', 'KronikHastalik__Myastenia_gravis', 'KronikHastalik__Hiportiroidizm', 'KronikHastalik__Aritmi', 'KronikHastalik__Limb-Girdle_Musküler_Distrofi', 'KronikHastalik__Hipertiroidizm', 'KronikHastalik__Astım', 'KronikHastalik__Duchenne_Musküler_Distrofisi', 'KronikHastalik__Kalp_yetmezliği', 'KronikHastalik__Fascioscapulohumeral_Distrofi', 'KronikHastalik__Hipertansiyon', 'KronikHastalik__Becker_Musküler_Distrofisi', 'KronikHastalik__Diyabet', 'KronikHastalik__Polimiyozit', 'KronikHastalik__Guatr', 'KronikHastalik__Hipotirodizm', 'KronikHastalik__count', 'Alerji__Polen', 'Alerji__POLEN', 'Alerji__Toz', 'Alerji__TOZ', 'Alerji__NOVALGIN', 'Alerji__Sucuk', 'Alerji__CORASPIN', 'Alerji__ARVELES', 'Alerji__Yer_Fıstığı', 'Alerji__Novalgin', 'Alerji__SUCUK', 'Alerji__GRİPİN', 'Alerji__VOLTAREN', 'Alerji__GRIPIN', 'Alerji__Voltaren', 'Alerji__Volteren', 'Alerji__count', 'Tanilar__DORSALJİ', 'Tanilar__DİĞER', 'Tanilar__tanımlanmamış', 'Tanilar__LUMBOSAKRAL_BÖLGE', 'Tanilar__İntervertebral_disk_bozuklukları', 'Tanilar__Omuzun_darbe_sendromu', 'Tanilar__SERVİKOTORASİK_BÖLGE', 'Tanilar__SERVİKAL_BÖLGE', 'Tanilar__Eklem_ağrısı', 'Tanilar__diğer', 'Tanilar__Dorsalji', 'Tanilar__Menisküs_yırtığı', 'Tanilar__şimdiki', 'Tanilar__Fibromiyalji', 'Tanilar__Radikülopati', 'Tanilar__Gonartroz_[diz_ekleminin_artrozu]', 'Tanilar__Kondromalazia_patella', 'Tanilar__Boyun_ağrısı', 'Tanilar__birden_fazla_yer', 'Tanilar__Ekstremite_ağrısı', 'Tanilar__count'], categorical=['Cinsiyet', 'KanGrubu', 'Uyruk', 'KronikHastalik', 'Bolum', 'Alerji', 'Tanilar', 'TedaviAdi', 'UygulamaYerleri', 'UygulamaSuresi']\n",
      "2025-09-06 21:51:52,525 - INFO - Model-ready CSV kaydedildi: Veysel\\model_ready.csv ve Veysel\\MODEL_READY.csv\n",
      "2025-09-06 21:51:52,541 - INFO - Pipeline tamamlandı. Tüm çıktılar Veysel içinde.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_files': {'summary_json': 'Veysel\\\\summary.json',\n",
       "  'eda_last_json': 'Veysel\\\\last.json',\n",
       "  'cleaned_csv': 'Veysel\\\\cleaned.csv',\n",
       "  'model_ready_csv': 'Veysel\\\\model_ready.csv',\n",
       "  'model_ready_csv_upper': 'Veysel\\\\MODEL_READY.csv',\n",
       "  'plots_dir': 'Veysel\\\\Plots'},\n",
       " 'multilabel_features': {'KronikHastalik': ['Myastenia gravis',\n",
       "   'Hiportiroidizm',\n",
       "   'Aritmi',\n",
       "   'Limb-Girdle Musküler Distrofi',\n",
       "   'Hipertiroidizm',\n",
       "   'Astım',\n",
       "   'Duchenne Musküler Distrofisi',\n",
       "   'Kalp yetmezliği',\n",
       "   'Fascioscapulohumeral Distrofi',\n",
       "   'Hipertansiyon',\n",
       "   'Becker Musküler Distrofisi',\n",
       "   'Diyabet',\n",
       "   'Polimiyozit',\n",
       "   'Guatr',\n",
       "   'Hipotirodizm'],\n",
       "  'Alerji': ['Polen',\n",
       "   'POLEN',\n",
       "   'Toz',\n",
       "   'TOZ',\n",
       "   'NOVALGIN',\n",
       "   'Sucuk',\n",
       "   'CORASPIN',\n",
       "   'ARVELES',\n",
       "   'Yer Fıstığı',\n",
       "   'Novalgin',\n",
       "   'SUCUK',\n",
       "   'GRİPİN',\n",
       "   'VOLTAREN',\n",
       "   'GRIPIN',\n",
       "   'Voltaren',\n",
       "   'Volteren'],\n",
       "  'Tanilar': ['DORSALJİ',\n",
       "   'DİĞER',\n",
       "   'tanımlanmamış',\n",
       "   'LUMBOSAKRAL BÖLGE',\n",
       "   'İntervertebral disk bozuklukları',\n",
       "   'Omuzun darbe sendromu',\n",
       "   'SERVİKOTORASİK BÖLGE',\n",
       "   'SERVİKAL BÖLGE',\n",
       "   'Eklem ağrısı',\n",
       "   'diğer',\n",
       "   'Dorsalji',\n",
       "   'Menisküs yırtığı',\n",
       "   'şimdiki',\n",
       "   'Fibromiyalji',\n",
       "   'Radikülopati',\n",
       "   'Gonartroz [diz ekleminin artrozu]',\n",
       "   'Kondromalazia patella',\n",
       "   'Boyun ağrısı',\n",
       "   'birden fazla yer',\n",
       "   'Ekstremite ağrısı']}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\"Talent_Academy_Case_DT_2025.xlsx\", outDir=\"OutputData\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pusulaTask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
